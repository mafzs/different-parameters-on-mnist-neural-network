# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zak2xnQW4rthvS9hG2UB0Kzu8TYxnQlg

at first we are going to import our libraries. our core library in this project is tensorflow
"""

import tensorflow as tf

print(tf.__version__)

"""at this project we will use the mnist data"""

mnist=tf.keras.datasets.mnist
(x_train,y_train),(x_test,y_test)=mnist.load_data()

"""we load our data from famous dataset called mnist that show the 0-9 hand written digits in 28*28 picture"""

print(x_train[0])

"""our data is brightness of each pixel in 28*28 squere that is shown in array."""

import matplotlib.pyplot as plt
plt.imshow(x_train[0],cmap=plt.cm.binary)
plt.show()

"""this is one of our data that it show number 5 :)"""

print(y_train[0])

"""as you see our brightness is number from 0-255 so at first we need to normalize our dataset to show them in range of 0-1(somtimes -1 to +1)"""

x_train=tf.keras.utils.normalize(x_train,axis=1)
x_test=tf.keras.utils.normalize(x_test,axis=1)

print(x_train[0])

"""now we are going to use some especific type of neural network that called sequential . when we know our data is ordered we can use sequential neural networks."""

model=tf.keras.models.Sequential()

"""at first we want to flatten our 2D picture to array of data with 784 value"""

model.add(tf.keras.layers.Flatten())

model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))

"""we are going to add another layer to better eficiency."""

model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))

"""now we are going to add the our output layer with 10 neurons that use softmax actvation function."""

model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))

"""now we are going to train our model and compile ti in this part we use typical settings but you can change it."""

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

model.fit(x_train, y_train, epochs=3)

model.fit(x_train, y_train, epochs=5)

val_loss, val_acc=model.evaluate(x_test,y_test)

print(val_loss)
print(val_acc)

"""after implementing our first neural network we are going to check effect of our parameters on the performance of the model,at first we check different number for epoch from 1-10 and check their effect on the performance of our model."""

l=[]
acc=[]
for i in [1,2,3,4,5,6,7,8,9]:
    model.fit(x_train,y_train,epochs=i)
    val_loss, val_acc=model.evaluate(x_test,y_test)
    l.append(i)
    acc.append(val_acc)

print(l)
print(acc)

"""now we are going to plot our data about effect of number epochs on the accuracy of the model ."""

plt.plot(l, acc, 'ro')
plt.ylabel('accuracy')
plt.xlabel('number of epoch')
plt.show()

"""as you see in the plot you can figure out that the number of epoch 4 has the best performance but the number of epochs show low corelation between model accuracy."""

i=1
l_numberlayer=[]
acc_num_layer=[]
while i <=5:
    new_model=tf.keras.models.Sequential()
    new_model.add(tf.keras.layers.Flatten())
    n=1
    while n<=i:
      new_model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))
      n+=1
    new_model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))
    new_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])
    new_model.fit(x_train, y_train, epochs=4)
    val_loss, val_acc=new_model.evaluate(x_test,y_test)
    l_numberlayer.append(i)
    acc_num_layer.append(val_acc)
    i+=1

"""in this part we are going to check the effect of depth on our model and we will check the accuracy of models with 1 to 5 layer and its performance ."""

print(l_numberlayer)
print(acc_num_layer)

plt.plot(l_numberlayer, acc_num_layer, 'ro')
plt.ylabel('accuracy')
plt.xlabel('number of layers')
plt.show()

"""we plot our data and as you see the 2 layer model work the best but we can not see good corelation between number of layers and accuracy."""

i=1
l_numberneuron=[]
acc_num_neuron=[]
while i <=10:
    new_model=tf.keras.models.Sequential()
    new_model.add(tf.keras.layers.Flatten())
    n=1
    while n<=2:
      new_model.add(tf.keras.layers.Dense(i,activation=tf.nn.relu))
      n+=1
    new_model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))
    new_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])
    new_model.fit(x_train, y_train, epochs=3)
    val_loss, val_acc=new_model.evaluate(x_test,y_test)
    l_numberneuron.append(i)
    acc_num_neuron.append(val_acc)
    i+=1

"""in our final experiment we will examine the effect of number of neurons in each layer (in 2 layer network) ."""

print(l_numberneuron)
print(acc_num_neuron)

plt.plot(l_numberneuron, acc_num_neuron, 'ro')
plt.ylabel('accuracy')
plt.xlabel('number of neurons in ech layer in nn with 2 layer')
plt.show()

"""finaly we plot our data and you can see that our performance grow with growth of the number of neurons in each layer."""